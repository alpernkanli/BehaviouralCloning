{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dense, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_Y(yuv_image):\n",
    "    random_y = 0.5 + np.random.uniform()\n",
    "    yuv_image[:,:,0] = yuv_image[:,:,0]*random_y\n",
    "    return yuv_image\n",
    "\n",
    "def horizontal_flip(image, angle):\n",
    "    flipped_image = cv2.flip(image, 1)\n",
    "    flipped_angle = angle*(-1)\n",
    "    return flipped_image, flipped_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log = pd.read_csv('./data/driving_log.csv')\n",
    "# X_train_paths = pd.concat([log['center'], log['left'], log['right']])\n",
    "X_train_paths = log['center']\n",
    "# y_train = pd.concat([log['steering'], log['steering']  + 0.08, log['steering'] - 0.08])\n",
    "y_train = log['steering']\n",
    "X_train_paths, X_valid_paths, y_train, y_valid = train_test_split(X_train_paths,\n",
    "                                                                 y_train,\n",
    "                                                                 test_size = 0.2)\n",
    "\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2 more image for every image.\n",
    "def augment_and_process(path, angle):\n",
    "    images = np.empty([3, 66, 200, 3])\n",
    "    angles = np.empty([3, 1])\n",
    "    \n",
    "    datapath = './data/' + path\n",
    "    datapath = datapath.replace(\" \", \"\")\n",
    "    \n",
    "    image = cv2.imread(datapath)\n",
    "    image = image[12:148, 0:320]\n",
    "    image = cv2.resize(image, (200, 66))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "    images[0] = image\n",
    "    images[1] = random_Y(image)\n",
    "    flipped_image, flipped_angle = horizontal_flip(image, angle)\n",
    "    images[2] = flipped_image\n",
    "    angles[0] = angle\n",
    "    angles[1] = angle\n",
    "    angles[2] = flipped_angle\n",
    "    return images, angles\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(X, Y):\n",
    "    while 1:\n",
    "        for batch in range(len(X_train_paths)//batch_size + 2):\n",
    "            batch = batch*batch_size\n",
    "            feature_batch = X[batch:batch + batch_size]\n",
    "            angle_batch = Y[batch:batch + batch_size]\n",
    "            images = []\n",
    "            angles = []\n",
    "            for (x, y) in zip(feature_batch, angle_batch):\n",
    "                image, angle = augment_and_process(x, y)\n",
    "                images.append(image)\n",
    "                angles.append(angle)\n",
    "            try:\n",
    "                images = np.vstack(images)\n",
    "                angles = np.vstack(angles)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            yield images, angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def the_model():\n",
    "    model = Sequential()\n",
    "    ch, row, col = 3, 66, 200\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.0,\n",
    "            input_shape=(row, col, ch)))\n",
    "    model.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode='same', init='normal', input_shape=(row, col, ch)))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Convolution2D(36, 5, 5, subsample=(2, 2), init='normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Convolution2D(48, 5, 5, subsample=(2, 2), init='normal'))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), init='normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), init='normal'))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Dense(100, name='Dense1', init='normal'))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Dense(50, name='Dense2', init='normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Dense(10, name='Dense3', init='normal'))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Dense(1, name='out'))\n",
    "    \n",
    "    adam = Adam(lr=1e-6)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_parameters(model):\n",
    "    model.save_weights('model.h5')\n",
    "    json_file = open('model.json', mode='w')\n",
    "    json.dump(model.to_json(), json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "19284/19284 [==============================] - 18s - loss: 0.0142 - val_loss: 0.0125\n",
      "Epoch 2/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 3/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 4/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 5/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 6/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0092 - val_loss: 0.0104\n",
      "Epoch 7/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0091 - val_loss: 0.0102\n",
      "Epoch 8/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0089 - val_loss: 0.0099\n",
      "Epoch 9/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0086 - val_loss: 0.0103\n",
      "Epoch 10/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0085 - val_loss: 0.0103\n",
      "Epoch 11/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 12/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0081 - val_loss: 0.0102\n",
      "Epoch 13/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 14/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0079 - val_loss: 0.0099\n",
      "Epoch 15/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 16/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0075 - val_loss: 0.0108\n",
      "Epoch 17/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0073 - val_loss: 0.0107\n",
      "Epoch 18/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 19/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0070 - val_loss: 0.0102\n",
      "Epoch 20/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0069 - val_loss: 0.0107\n",
      "Epoch 21/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0065 - val_loss: 0.0101\n",
      "Epoch 22/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0065 - val_loss: 0.0105\n",
      "Epoch 23/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0062 - val_loss: 0.0102\n",
      "Epoch 24/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0060 - val_loss: 0.0106\n",
      "Epoch 25/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0059 - val_loss: 0.0111\n",
      "Epoch 26/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0057 - val_loss: 0.0103\n",
      "Epoch 27/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0055 - val_loss: 0.0105\n",
      "Epoch 28/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 29/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0053 - val_loss: 0.0102\n",
      "Epoch 30/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0050 - val_loss: 0.0106\n",
      "Epoch 31/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 32/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0048 - val_loss: 0.0102\n",
      "Epoch 33/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0047 - val_loss: 0.0104\n",
      "Epoch 34/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0045 - val_loss: 0.0106\n",
      "Epoch 35/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0045 - val_loss: 0.0106\n",
      "Epoch 36/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0043 - val_loss: 0.0104\n",
      "Epoch 37/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0042 - val_loss: 0.0102\n",
      "Epoch 38/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0041 - val_loss: 0.0108\n",
      "Epoch 39/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0040 - val_loss: 0.0106\n",
      "Epoch 40/40\n",
      "19284/19284 [==============================] - 16s - loss: 0.0041 - val_loss: 0.0105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdaa0a6bac8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = the_model()\n",
    "epochs = 40\n",
    "model.fit_generator(generator(X_train_paths, y_train), \n",
    "                    samples_per_epoch= 3*X_train_paths.shape[0],\n",
    "                    nb_epoch=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=generator(X_valid_paths, y_valid),\n",
    "                    nb_val_samples=3*X_valid_paths.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3k]",
   "language": "python",
   "name": "conda-env-py3k-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
